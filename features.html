<!doctype html>
<html>
<head>
<meta charset="utf-8">
<title>Features</title>
<link rel='stylesheet prefetch' href='https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css'>
<link rel="stylesheet" href="interface.css">
</head>

<body>
<div id="page">

<nav id="navigation">
   <a href="index.html">HOME</a>
   <a>FEATURES</a>
   <a href="media.html">MEDIA</a>
   <a>TEAM</a>
   <a>CONTACT</a>
   <a href="http://www.robocupathome.org/">ROBOCUP</a>
</nav>

<h2>Features</h2>
<h3>SLAM (Simultaneous Localization And Mapping)</h3>
	<p> The localization and mapping of a dynamic environment is has been done previously using the RGBD SLAM algoritm.
		A better visual -SLAM algorithm, the ORB SLAM will be implemented now using a Kinect sensor</p>
	<p><b> ORB-SLAM Overview </b></p>
	<ul>
		<li>Feature Choice -> ORB features</li>
		<li>Three Threads: Tracking, Local Mapping and Loop Closing -> Run in parallel</li>
		<li>Map Points, Key Frames and their Selection:
			<br>Stores  world coordinate system, viewing system, representative ORB descriptor; camera pose, camera intrinsics like focal length and principal point</br></li> 
		<li>Co-visibility Graph and Essential Graph
			<br>Each node is a key frame and an edge between two key frames exists if they share observations of the same map points</br></li>
		<li>Bags of Words Place Recognition -> To perform loop detection and re-localization
			<br>visual vocabulary is created offline with the ORB descriptors extracted from a large set of images</br></li>
	</ul>

		
<h3>Voice based modules</h3>
<p>To interact with the people around, in a dynamic environment voice based modules will be integrated with other modules.

Voice based modules comprise of :

* Voice recognition

* Voice localization

* Voice synthesis

To carry out voice based tasks or tasks which require human robot interaction, three microphones will be integrated with the hardware, 120 degrees apart and a kinect sensor. HARK, open source robot software for voice modules i.e. voice localization, automatic recognition and voice synthesis will be used.

Using HARK will enable the robot to understand what the user says. after understanding it will be able to respond(reply and perform actions) accordingly and the robot will be able to distinguish different voices or voices coming from different positions. Hark will provide real time processing.<p>
<h3>Facial Recognition</h3>
<h3>Object Detection and Manipulation</h3>
<h3>Mechanical Structure and Analysis</h3>

   <script src='http://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js'></script>
	<script src='https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js'></script>

	
</div>
</body>
</html>
